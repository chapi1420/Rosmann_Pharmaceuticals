{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sales Prediction Model Documentation\n",
    "\n",
    "This document provides an overview of the Sales Prediction Model, which uses both Random Forest and LSTM to predict sales based on various features. \n",
    "\n",
    "## Overview\n",
    "\n",
    "The model processes sales data, merges it with store information, preprocesses it, builds a machine learning pipeline, trains the model, and saves it for future use. \n",
    "\n",
    "## 1. Importing Libraries\n",
    "\n",
    "The necessary libraries are imported for data manipulation, machine learning, and logging. Key libraries include:\n",
    "- **pandas** for data manipulation.\n",
    "- **numpy** for numerical operations.\n",
    "- **scikit-learn** for building machine learning models and preprocessing data.\n",
    "- **tensorflow.keras** for deep learning tasks (specifically for LSTM).\n",
    "- **joblib** for saving trained models.\n",
    "- **logging** for tracking the execution process and any issues.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('..'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.modeling import SalesPrediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"C:\\\\Users\\\\nadew\\\\10x\\\\week4\\\\Rosmann\\\\rossmann-store-sales\\\\processed_train_data.csv\"\n",
    "test_path = \"C:\\\\Users\\\\nadew\\\\10x\\\\week4\\\\Rosmann\\\\rossmann-store-sales\\\\processed_test_data.csv\"\n",
    "store_path = \"C:\\\\Users\\\\nadew\\\\10x\\\\week4\\\\Rosmann\\\\rossmann-store-sales\\\\store.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## 2. SalesPrediction Class\n",
    "\n",
    "### Initialization\n",
    "The `SalesPrediction` class is designed to encapsulate all functionalities related to sales prediction. It initializes with paths to the training, testing, and store data. It also sets up placeholders for data and the model pipeline, along with a scaler for feature scaling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SalesPrediction(train_path, test_path, store_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and Merging Data\n",
    "The method responsible for loading and merging data reads the training, testing, and store datasets from specified file paths. It merges the training and testing data with the store data based on a common column, ensuring that all relevant information is available for modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_and_merge_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Preparation\n",
    "This method prepares the features for modeling by applying preprocessing to both training and testing datasets. It ensures that the data is clean and ready for analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.prepare_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model Pipeline\n",
    "A machine learning pipeline is constructed, which includes:\n",
    "- **Numeric Features**: These are scaled using a StandardScaler to normalize the data.\n",
    "- **Categorical Features**: These are transformed using OneHotEncoder to convert categorical variables into a format suitable for modeling.\n",
    "- **Model**: A RandomForestRegressor is utilized as the regression model, encapsulated within the pipeline to streamline the training process.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_pipeline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "The model training process involves:\n",
    "- Splitting the training data into features and target variables.\n",
    "- Further dividing the data into training and validation sets to evaluate model performance.\n",
    "- Fitting the model pipeline to the training data and logging the performance metrics (Mean Absolute Error and Mean Squared Error) on the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Model\n",
    "Once the model is trained, it is saved to a file with a timestamp in its name. This allows for easy versioning and retrieval of the trained model later, ensuring that the best-performing model can be accessed when needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LSTM Model\n",
    "Although the LSTM training method is included in the code, it focuses on preparing time series data, building the LSTM model, training, and saving it. This part is designed for scenarios where sequential data is analyzed, providing a different approach to sales prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nadew\\10x\\week4\\Rosmann\\env4\\lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "\u001b[1m22251/22251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 13ms/step - loss: 0.0061 - val_loss: 0.0043\n",
      "Epoch 2/4\n",
      "\u001b[1m22251/22251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m409s\u001b[0m 18ms/step - loss: 0.0050 - val_loss: 0.0044\n",
      "Epoch 3/4\n",
      "\u001b[1m22251/22251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0042\n",
      "Epoch 4/4\n",
      "\u001b[1m22251/22251\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m263s\u001b[0m 12ms/step - loss: 0.0049 - val_loss: 0.0043\n",
      "\u001b[1m9537/9537\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 4ms/step - loss: 0.0042\n"
     ]
    }
   ],
   "source": [
    "model.train_lstm()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "The Sales Prediction Model effectively combines data preprocessing, machine learning, and deep learning techniques to predict sales. By organizing the code into a class structure and employing pipelines, the model is both efficient and scalable, allowing for future enhancements and adaptations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
